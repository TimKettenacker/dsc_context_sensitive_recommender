test2 <- strsplit(test1, "\n| ", fixed = TRUE)
test2
test1 <- gsub("\\[|\\]|\\{|\\}", "", wiki_content$parse$wikitext$`*`)
test1
test2 <- strsplit(test1, "\n| ", fixed = TRUE)
test2
rm(test1)
rm(test2)
cat("\014")
test1 <- gsub("\\[|\\]|\\{|\\}", "", wiki_content$parse$wikitext$`*`)
test1
str_match(test1, "industry = [A-Za-z]+")
str_match(test1, "industry = [A-Za-z]+")[1,1]
str_match(test1, "product = [A-Za-z]+")
str_match(test1, "products = [A-Za-z]+")
cleansed_content <- gsub("\\[|\\]|\\{|\\}", "", wiki_content$parse$wikitext$`*`)
cleansed_content[[1]]
cleansed_content
str_match(cleansed_content, "industry = [A-Za-z]+")
grep(cleansed_content, "industry = [A-Za-z]+")
agrep(cleansed_content, "industry = [A-Za-z]+")
??grep
agrep("industry = [A-Za-z]+", cleansed_content)
agrep("industry = [A-Za-z]+", cleansed_content, fixed = TRUE)
agrep("industry = [A-Za-z]+", cleansed_content, fixed = TRUE, value = TRUE)
cat("\014")
str_match(cleansed_content, "industry = [A-Za-z]+")
industry <- str_match(cleansed_content, "industry = [A-Za-z]+")
View(industry)
industry <- str_match(cleansed_content, "industry = [A-Za-z]+")[1,1]
sub("industry = ", "", industry)
str_match(cleansed_content, "industry = [A-Za-z]+")[1,1] %>% sub("industry = ", "")
cleansed_content >%> str_match("industry = [A-Za-z]+")[1,1] %>% sub("industry = ", "")
cleansed_content %>% str_match("industry = [A-Za-z]+")[1,1] %>% sub("industry = ", "")
cleansed_content %>% str_match(pattern = "industry = [A-Za-z]+")[1,1] %>% sub("industry = ", "")
cleansed_content %>% str_match(cleansed_content, pattern = "industry = [A-Za-z]+")[1,1] %>% sub("industry = ", "")
cat("\014")
library(stringr)
find_enrichment_categories <- function(cleansed_content){
industry_value <- str_match(cleansed_content, "industry = [A-Za-z]+")[1,1]
industry_value <- sub("industry = ", "", industry)
return(industry_value)
}
find_enrichment_categories(cleansed_content)
library(stringr)
find_enrichment_category4industry <- function(cleansed_content){
industry_value <- str_match(cleansed_content, "industry = [A-Za-z]+")[1,1]
industry_value <- sub("industry = ", "", industry)
return(industry_value)
}
find_enrichment_category4industry <- function(cleansed_content){
industry_value <- str_match(cleansed_content, "industry = [A-Za-z]+")[1,1]
industry_value <- sub("industry = ", "", industry_value)
return(industry_value)
}
find_enrichment_category4industry(cleansed_content)
find_enrichment_category4products <- function(cleansed_content){
products_value <- str_match(cleansed_content, "products = [A-Za-z]+")[1,1]
products_value <- sub("products = ", "", products_value)
return(industry_value)
}
find_enrichment_category4products(cleansed_content)
find_enrichment_category4products <- function(cleansed_content){
products_value <- str_match(cleansed_content, "products = [A-Za-z]+")[1,1]
products_value <- sub("products = ", "", products_value)
return(products_value)
}
find_enrichment_category4products(cleansed_content)
str_match(cleansed_content, "industry = [A-Za-z]")[1,1]
str_match(cleansed_content, "industry = [A-Za-z]*")[1,1]
str_match(cleansed_content, "industry = [A-Za-z]*+")[1,1]
str_match(cleansed_content, "products = [A-Za-z]*+")[1,1]
str_match(cleansed_content, "products = [A-Za-z]*")[1,1]
str_match(cleansed_content, "products = [A-Za-z]\s")[1,1]
str_match(cleansed_content, "products = [A-Za-z]+\s")[1,1]
str_match(cleansed_content, "products = [A-Za-z]*\s")[1,1]
str_match(cleansed_content, "products = [A-Za-z]*s")[1,1]
str_match(cleansed_content, "products = [A-Za-z]*w")[1,1]
str_match(cleansed_content, "products = [A-Za-z]*s")[1,1]
str_match(cleansed_content, "products = [A-Za-z]*s[A-Za-z]")[1,1]
str_match(cleansed_content, "products = [A-Za-z]*s")[1,1]
str_match(cleansed_content, "industry = [A-Za-z]*s")[1,1]
str_match(cleansed_content, "products = w")[1,1]
str_match(cleansed_content, "products = \w")[1,1]
str_match(cleansed_content, "industry = [A-Za-z]+")[1,1]
str_match(cleansed_content, "industry = [A-Za-z]+")
str_match(cleansed_content, "industry = [A-Za-z]+{n,}")
str_match(cleansed_content, "industry = [A-Za-z]+"{n,})
str_match(cleansed_content, "industry = [A-Za-z]++")
str_match(cleansed_content, "products = [A-Za-z]++")
str_match(cleansed_content, "products = [A-Za-z]D")
str_match(cleansed_content, "products = [A-Za-z]")
str_match(cleansed_content, "products = [A-Za-z]\D")
str_match(cleansed_content, "products = [A-Za-z].")
str_match(cleansed_content, "products = [.]++")
str_match(cleansed_content, "products = [A-Za-z]++")
str_match(cleansed_content, "products = [A-Za-z]++\\s")
str_match(cleansed_content, "products = [A-Za-z]++\\s[A-Za-z]")
str_match(cleansed_content, "products = [A-Za-z]++\\s[A-Za-z]++")
str_match(cleansed_content, "products = [A-Za-z]++\\s[A-Za-z]++\\s[A-Za-z]++")
str_match(cleansed_content, "products = [A-Za-z]++\\s[A-Za-z]++\\s[A-Za-z]++\\s[A-Za-z]++")
str_match(cleansed_content, "products = [A-Za-z]++\\s[A-Za-z]++\\s[A-Za-z]++")
str_match(cleansed_content, "products = \\w")
str_match(cleansed_content, "products = \\w++")
str_match(cleansed_content, "products = \\w++\s")
str_match(cleansed_content, "products = \\w+\s")
str_match(cleansed_content, "products = \\w++\\s")
str_match(cleansed_content, "products = \\w++\\s{1,}")
str_match(cleansed_content, "products = \\w++\\s\\w++")
str_match(cleansed_content, "products = \\w++\\s(?=\\w)")
str_match(cleansed_content, "products = \\w++\\s")
str_extract(cleansed_content, "products = \\w++\\s")
str_extract_all(cleansed_content, "products = \\w++\\s")
str_extract(cleansed_content, "products = \\w++\\s")
str_extract(cleansed_content, "products = \\b")
str_extract(cleansed_content, "products = \\w++\\b")
str_extract(cleansed_content, "products = [:alpha:]")
str_extract(cleansed_content, "products = [:alpha:]*")
str_extract(cleansed_content, "products = [:alpha:]+")
str_extract(cleansed_content, "products = [:alpha:]<<+")
str_extract(cleansed_content, "products = [:alpha:]*")
str_extract_all(cleansed_content, "products = [:alpha:]*")
str_extract(cleansed_content, "products = [:alpha:]*")
str_extract(cleansed_content, "products = [:alpha:]*")
str_extract(cleansed_content, "products = [:alpha:]*[:punct:]")
str_extract(cleansed_content, "products = [:alpha:][:punct:]")
str_extract(cleansed_content, "products = [:alpha:]++[:punct:]")
str_extract(cleansed_content, "products = [:alpha:]++\\[:punct:]")
str_extract(cleansed_content, "products = [:alpha:]+")
str_extract(cleansed_content, "products = [:alpha:]+.")
str_extract(cleansed_content, "industry = [:alpha:]+.")
str_extract(cleansed_content, "industry = [:alpha:]+.{0,}")
str_extract(cleansed_content, "products = [:alpha:]+.{0,}")
str_extract(cleansed_content, "products = [:alpha:]+{0,}")
str_extract(cleansed_content, "products = [:alpha:].{0,}")
str_extract(cleansed_content, "products = [:alpha:]")
str_extract(cleansed_content, "products = [:alpha:].{0,}")
str_extract(cleansed_content, "industry = [:alpha:].{0,}")
cleansed_content
test <- "Veterinary drugs, diagnostic imaging, general"
test <- "products = Veterinary drugs, diagnostic imaging, general"
str_extract(test, "products = [:alpha:].{0,}")
library(stringr)
find_enrichment_category4industry <- function(cleansed_content){
industry_value <- str_extract(cleansed_content, "industry = [:alpha:]+.{0,}")
industry_value <- sub("industry = ", "", industry_value)
return(industry_value)
}
find_enrichment_category4products <- function(cleansed_content){
products_value <- str_extract(cleansed_content, "products = [:alpha:]+.{0,}")
products_value <- sub("products = ", "", products_value)
return(products_value)
}
find_enrichment_category4industry(cleansed_content)
find_enrichment_category4products(cleansed_content)
test1 <- find_enrichment_category4products(cleansed_content)
str(test1)
cat("\014")
library(jsonlite)
fromJSON("https://api.datamuse.com/words?rel_gen=assessment&topics=company&max=3")
?cat
?paste
link_p1 <- "https://api.datamuse.com/words?rel_gen="
link_p2 <- "&topics=company&max=3"
paste0(link_p1, "Proposal", link_p2)
api_link <- paste0("https://api.datamuse.com/words?rel_gen=", "Proposal", "&topics=company&max=3")
api_link
fromJSON(api_link)
api_out <- fromJSON(api_link)
View(api_out)
cat("\014")
library(tm)
install.packages("tm")
library(tm)
?list.files
??tm
??´tm´
?tm
??Package:tm
cat("c\014")
require("WikipediR")
require("WikidataR")
require("stringr")
require("jsonlite")
setwd("/Users/timkettenacker/dsproj_repos/R/dsc_context_sensitive_recommender")
find_item("Hadoop")
find_item("Big Data")
find_item("BI")
find_item("MDM")
find_item("Tableau")
find_item("Flink")
find_item("Talend")
item <- find_item("Hadoop")
item
item[1]
id <- grep("data|information|computing|distributed|processing|technology|Apache|software", item
)
get_property(id = item[[id]]$id)
item <- find_item("BI")
item
id <- grep("data|information|computing|distributed|processing|technology|Apache|software", item)
id
item <- c("Hallo")
id <- grep("data|information|computing|distributed|processing|technology|Apache|software", item)
item <- find_item("Solvay")
id <- grep("company|manufacturer|corporation", item)
item <- find_item("BI")
item
id <- grep("data", item)
id <- grep("technology", item)
id <- grep("information", item)
item
length(item)
for(e in 1:length(item)){
id <- grep("data|information|computing|distributed|processing|technology|Apache|software", item[[e]]$description)
}
id
for(e in 1:length(item)){
print(item[[e]]$description)
}
grep("data", item[[5]]$description)
grep("data", item$description)
grep("data", item[[3]]$description)
for(e in 1:length(item)){
print(grep("data|information|computing|distributed|processing|technology|Apache|software", item[[e]]$description))
}
?grep
for(e in 1:length(item)){
print(grep("data|information|computing|distributed|processing|technology|Apache|software", item[[e]]$description, value = TRUE))
}
buzzwords <- c("")
?append
?lappend
buzzwords <- c("")
check4buzzwords <- function(arg){
item <- find_item(arg, limit = 10)
for(e in 1:length(item)){
append(buzzwords, grep("data|information|computing|distributed|processing|technology|Apache|software", item[[e]]$description, value = TRUE))
}
#return(company)
}
check4buzzwords("BI")
buzzwords
buzzwords <- c("")
check4buzzwords <- function(arg){
item <- find_item(arg, limit = 10)
for(e in 1:length(item)){
buzzwords <- append(buzzwords, grep("data|information|computing|distributed|processing|technology|Apache|software", item[[e]]$description, value = TRUE))
}
#return(company)
}
buzzwords
check4buzzwords("BI")
buzzwords
check4buzzwords <- function(arg){
buzzwords <- c("")
item <- find_item(arg, limit = 10)
for(e in 1:length(item)){
buzzwords <- append(buzzwords, grep("data|information|computing|distributed|processing|technology|Apache|software", item[[e]]$description, value = TRUE))
}
return(buzzwords)
}
check4buzzwords("BI")
check4buzzwords <- function(arg){
buzzwords <- c(NA)
item <- find_item(arg, limit = 10)
for(e in 1:length(item)){
buzzwords <- append(buzzwords, grep("data|information|computing|distributed|processing|technology|Apache|software", item[[e]]$description, value = TRUE))
}
return(buzzwords)
}
check4buzzwords("BI")
check4buzzwords <- function(arg){
buzzwords <- c()
item <- find_item(arg, limit = 10)
for(e in 1:length(item)){
buzzwords <- append(buzzwords, grep("data|information|computing|distributed|processing|technology|Apache|software", item[[e]]$description, value = TRUE))
}
return(buzzwords)
}
check4buzzwords("BI")
check4buzzwords("Hadoop")
check4buzzwords("Hydrokultur")
args <- c("Hadoop", "Pharmacy", "BASF", "implementation")
args <- args[args != "Capgemini"]
industry <- ""
products <- ""
relevant_terms <- ""
# checks if any returned item fits a company description
# and returns the wikidata item
check4company <- function(arg){
item <- find_item(arg, limit = 10)
id <- grep("company|manufacturer|corporation", item)
company <- get_property(id = item[[id]]$id)
return(company)
}
get_wikipedia_data <- function(item){
wiki_content <- page_content("en", "wikipedia", page_name = item[[1]]$sitelinks$enwiki$title, as_wikitext = TRUE)
wiki_content <- gsub("\\[|\\]|\\{|\\}", "", wiki_content$parse$wikitext$`*`)
return(wiki_content)
}
# extracting "industry" and "products" as enrichment categories
find_enrichment_category4industry <- function(wiki_content){
industry_value <- str_extract(wiki_content, "industry\\s+= [:alpha:]+.{0,}")
industry_value <- sub("industry\\s+=", "", industry_value)
return(industry_value)
}
find_enrichment_category4products <- function(wiki_content){
products_value <- str_extract(wiki_content, "products\\s+= [:alpha:]+.{0,}")
products_value <- sub("products\\s+=", "", products_value)
return(products_value)
}
check4buzzwords <- function(arg){
buzzwords <- c()
item <- find_item(arg, limit = 10)
for(e in 1:length(item)){
buzzwords <- append(buzzwords, grep("data|information|computing|distributed|processing|technology|Apache|software", item[[e]]$description, value = TRUE))
}
return(buzzwords)
}
# start conditional enrichment on user input data
for(arg in args){
item <- tryCatch(check4company(arg), error=function(e){})
# check if any returned item fits a company description and if so, subsequently add enriching features
if(is.null(item) == FALSE){
wiki_content <- get_wikipedia_data(item)
industry <- append(find_enrichment_category4industry(wiki_content), industry)
products <- append(find_enrichment_category4products(wiki_content), products)
} # if no match to a business term on wikipedia could be made, look for related words
else{
relevant_terms <- append(check4buzzwords(arg), relevant_terms)
}
}
buffed_args <- paste(c(args, industry, products, relevant_terms))
buffed_args
find_item("BASF")
check4company("BASF")
check4company("Solvay")
check4company("basf")
item <- check4company("BASF")
item <- find_item("BASF")
item
grep("company|manufacturer|corporation", item)
id <- grep("company|manufacturer|corporation", item)
company <- get_property(id = item[[id]]$id)
id
if(id > 2){print("y")}
length(id)
if(length(id) > 1){print("a")}
id[1]
id[2]
check4company <- function(arg){
item <- find_item(arg, limit = 10)
id <- grep("company|manufacturer|corporation", item)
if(length(id) > 1){
id <- id[1]
}
company <- get_property(id = item[[id]]$id)
return(company)
}
args
industry <- ""
products <- ""
relevant_terms <- ""
# checks if any returned item fits a company description
# and returns the wikidata item
check4company <- function(arg){
item <- find_item(arg, limit = 10)
id <- grep("company|manufacturer|corporation", item)
if(length(id) > 1){
id <- id[1]
}
company <- get_property(id = item[[id]]$id)
return(company)
}
get_wikipedia_data <- function(item){
wiki_content <- page_content("en", "wikipedia", page_name = item[[1]]$sitelinks$enwiki$title, as_wikitext = TRUE)
wiki_content <- gsub("\\[|\\]|\\{|\\}", "", wiki_content$parse$wikitext$`*`)
return(wiki_content)
}
# extracting "industry" and "products" as enrichment categories
find_enrichment_category4industry <- function(wiki_content){
industry_value <- str_extract(wiki_content, "industry\\s+= [:alpha:]+.{0,}")
industry_value <- sub("industry\\s+=", "", industry_value)
return(industry_value)
}
find_enrichment_category4products <- function(wiki_content){
products_value <- str_extract(wiki_content, "products\\s+= [:alpha:]+.{0,}")
products_value <- sub("products\\s+=", "", products_value)
return(products_value)
}
check4buzzwords <- function(arg){
buzzwords <- c()
item <- find_item(arg, limit = 10)
for(e in 1:length(item)){
buzzwords <- append(buzzwords, grep("data|information|computing|distributed|processing|technology|Apache|software", item[[e]]$description, value = TRUE))
}
return(buzzwords)
}
# start conditional enrichment on user input data
for(arg in args){
item <- tryCatch(check4company(arg), error=function(e){})
# check if any returned item fits a company description and if so, subsequently add enriching features
if(is.null(item) == FALSE){
wiki_content <- get_wikipedia_data(item)
industry <- append(find_enrichment_category4industry(wiki_content), industry)
products <- append(find_enrichment_category4products(wiki_content), products)
} # if no match to a business term on wikipedia could be made, look for related words
else{
relevant_terms <- append(check4buzzwords(arg), relevant_terms)
}
}
buffed_args <- paste(c(args, industry, products, relevant_terms))
buffed_args
require("officer")
setwd("/Users/timkettenacker/dsproj_repos/R/dsc_context_sensitive_recommender")
# there is an error in the officer package which causes loops to break if trying to read any other than "pptx", like i.e. outdated "ppt"
# apparently, it cannot be skipped in tryCatch, that's why it has to be handled beforehand
files_path <- list.files(path = "/Users/timkettenacker/Downloads/GDSCDataSet/Presentations")
file_names <- grep("pptx", files_path, value = TRUE, fixed = TRUE)
didnt_read <- setdiff(files_path, file_names)
pptx_content <- as.data.frame(file_names, stringsAsFactors = FALSE)
pptx_content$content <- c("")
for(i in 1:length(pptx_content$file_names)){
tryCatch(
slides <- data.frame(),
slides <- slide_summary(read_pptx(paste0("/Users/timkettenacker/Downloads/GDSCDataSet/Presentations/", pptx_content$file_names[i]))),
error=function(e){print(pptx_content$file_names[i])},
pptx_content$content[i] <- paste0(slides$text, collapse = " ")
)
}
require("quanteda")
setwd("/Users/timkettenacker/dsproj_repos/R/dsc_context_sensitive_recommender")
dict <- dictionary(list(search_term = buffed_args))
dfm <- dfm(pptx_content$content, remove = stopwords("english"), remove_punct = TRUE, tolower = TRUE)
lookup <- dfm_lookup(dfm, dict, valuetype = "glob", exclusive = FALSE)
result_matrix <- as.matrix(lookup)
result_matrix <- result_matrix[order(result_matrix[,1], decreasing = TRUE),]
# calculate text distances afterwards or just return ordered list
top7 <- result_matrix[1:7, 1]
top7 <- sub("[a-z]+", "", names(top7))
print(pptx_content$file_names[as.integer(top7)])
View(result_matrix)
View(pptx_content)
View(result_matrix)
buffed_args
dict
View(result_matrix)
result_matrix[[1]]
result_matrix[["bi"]]
result_matrix["bi"]
result_matrix["bi",]
dfm(buffed_args, remove = stopwords("english"), remove_punct = TRUE, tolower = TRUE)
View(dfm(buffed_args, remove = stopwords("english"), remove_punct = TRUE, tolower = TRUE))
paste0(buffed_args)
View(dfm(paste0(buffed_args), remove = stopwords("english"), remove_punct = TRUE, tolower = TRUE))
View(dfm(paste0(buffed_args, collapse = TRUE), remove = stopwords("english"), remove_punct = TRUE, tolower = TRUE))
View(dfm(paste(buffed_args, collapse = TRUE), remove = stopwords("english"), remove_punct = TRUE, tolower = TRUE))
?paste
View(dfm(paste0(buffed_args, collapse = ""), remove = stopwords("english"), remove_punct = TRUE, tolower = TRUE))
View(dfm(paste0(buffed_args, collapse = " "), remove = stopwords("english"), remove_punct = TRUE, tolower = TRUE))
View(dfm(paste0(buffed_args, collapse = " "), remove = stopwords("english"), remove_punct = TRUE, tolower = TRUE))
View(dfm(paste0(buffed_args, collapse = TRUE), remove = stopwords("english"), remove_punct = TRUE, tolower = TRUE))
View(dfm(pptx_content$content, remove = stopwords("english"), remove_punct = TRUE, tolower = TRUE))
View(dfm(paste0(buffed_args, collapse = TRUE), remove = stopwords("english"), remove_punct = TRUE, tolower = TRUE))
View(dfm(paste0(buffed_args, collapse = " "), remove = stopwords("english"), remove_punct = TRUE, tolower = TRUE))
plot(dfm(paste0(buffed_args, collapse = " "), remove = stopwords("english"), remove_punct = TRUE, tolower = TRUE))
?dfm_smooth
dfm_arg <- dfm(paste0(buffed_args, collapse = " "), remove = stopwords("english"), remove_punct = TRUE, tolower = TRUE)
view(dfm_arg)
View(dfm_arg)
View(dfm_smooth(dfm_arg, type=c("tfidf")))
dfm_smooth(dfm_arg, type=c("tfidf"))
dfm_smooth(dfm_arg, type=c("tfidf"), weights = NULL)
dfm_weight(dfm_arg, type=c("tfidf"), weights = NULL)
View(dfm_weight(dfm_arg, type=c("tfidf"), weights = NULL))
View(dfm_weight(lookup, type=c("tfidf"), weights = NULL))
require(topicmodels)
install.packages("topicmodels")
require(topicmodels)
myLDAfit20 <- LDA(convert(dfm, to = "topicmodels"), k = 20)
View(myLDAfit20)
get_terms(myLDAfit20, 5)
buffed_args <- paste(c(args, industry, products, relevant_terms))
dict <- dictionary(list(search_term = buffed_args))
dict
dfm <- dfm(pptx_content$content, remove = stopwords("english"), remove_punct = TRUE, tolower = TRUE)
lookup <- dfm_lookup(dfm, dict, valuetype = "glob", exclusive = FALSE)
result_matrix <- as.matrix(lookup)
result_matrix <- result_matrix[order(result_matrix[,1], decreasing = TRUE),]
View(result_matrix)
myLDAfit20 <- LDA(convert(dfm, to = "topicmodels"), k = 100)
get_terms(myLDAfit20, 100)
?docvars
docvars(buffed_args)
docvars(dfm(paste0(buffed_args, collapse = " "), remove = stopwords("english"), remove_punct = TRUE, tolower = TRUE))
test <- docvars(dfm(paste0(buffed_args, collapse = " "), remove = stopwords("english"), remove_punct = TRUE, tolower = TRUE))
test
View(test)
?setdiff
library(tm)
pptx_content$content[1]
test <- tidy(pptx_content$content[1])
library(tidytext)
install.packages("tidytext")
library(tidytext)
test <- tidy(pptx_content$content[1])
View(test)
test
test <- tidy(dfm)
View(test)
View(test)
